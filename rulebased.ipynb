{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KK9UC_4okX5",
        "outputId": "f974e724-e37e-4fa3-f5ce-342317c891d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ClfrJFJo4lS",
        "outputId": "7d98fe4f-c02a-4b95-ed1c-fadd17f2540a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.2)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.32.3)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2024.8.30)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.16.1)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13539 sha256=9e4487af742ecb6d07f4b6bbc932987bf55835b03307fb034957a511b7416131\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3342 sha256=e4a60896be095b6d061e1a074c12a7b7242139f2df06fe9627bd7d52da812725\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398379 sha256=6aaaf037a6a41466082d9f9ecdaf64d5c0840ef2a15c8dfa834bb53728cda0e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=09b62765991298bc39262b0d05613f1ba3a422ee22791bb71678f77a076a3ded\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "p-QCz60mpLTK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt',quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OthXsafp3tZ",
        "outputId": "3aefd61f-7714-458b-f1c8-2a3ebbe4569d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article=Article(\"https://abcnews.go.com/Sports\")\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "corpus=article.text"
      ],
      "metadata": {
        "id": "qnAFQSiCqVPD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDH_KVSrrg6T",
        "outputId": "214c015c-af44-4132-8d72-4ebd24c5bcfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUSTIN -- Lando Norris will start from pole position at the U.S. Grand Prix after a George Russell crash in qualifying brought an early end to the session just as Max Verstappen looked on course to beat the McLaren driver to the fastest time. Verstappen, who leads Norris by 54 points in the drivers' standings after his sprint race victory on Saturday, was on a faster lap than his title rival when Russell crashed at the penultimate corner and brought out yellow flags that effectively ended the session. Norris' was 0.031 seconds faster than Verstappen after their first runs in Q3, meaning he secured pole position when the session ended. Informed of the result over the team radio, he said: \"F---ing beautiful!\" After the session, Norris said: \"It was a beautiful lap, I was not going to go much quicker than what I did -- you know when you just do a lap and you think it's going to be tough to beat that. I put everything out on the line and we've been on the backfoot all weekend, we've...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=corpus\n",
        "sentence_list=nltk.sent_tokenize(text)"
      ],
      "metadata": {
        "id": "wulj7lwRrmLg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2B8_7DBr3RR",
        "outputId": "7ae18a65-84e5-4a4d-e7c6-929fa3243873"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AUSTIN -- Lando Norris will start from pole position at the U.S. Grand Prix after a George Russell crash in qualifying brought an early end to the session just as Max Verstappen looked on course to beat the McLaren driver to the fastest time.', \"Verstappen, who leads Norris by 54 points in the drivers' standings after his sprint race victory on Saturday, was on a faster lap than his title rival when Russell crashed at the penultimate corner and brought out yellow flags that effectively ended the session.\", \"Norris' was 0.031 seconds faster than Verstappen after their first runs in Q3, meaning he secured pole position when the session ended.\", 'Informed of the result over the team radio, he said: \"F---ing beautiful!\"', 'After the session, Norris said: \"It was a beautiful lap, I was not going to go much quicker than what I did -- you know when you just do a lap and you think it\\'s going to be tough to beat that.', \"I put everything out on the line and we've been on the backfoot all weekend, we've...\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greeting_response(text):\n",
        "  text=text.lower()\n",
        "  bot_greeting=[\"hi\",\"hello\",\"hey\"]\n",
        "  user_greetings=[\"hi\",\"hello\",\"hey\",\"hello everyone\",\"greeting\",\"welcome\"]\n",
        "\n",
        "  for word in text.split():\n",
        "   if word in user_greetings:\n",
        "    return random.choice(bot_greeting)"
      ],
      "metadata": {
        "id": "kRRvCbfsr_MR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_sort(list_var):\n",
        "  length=len(list_var)\n",
        "  list_index=list(range(0,length))\n",
        "  x=list_var\n",
        "  for i in range(length):\n",
        "    for j in range(length):\n",
        "     if x[list_index[i]]>x[list_index[j]]:\n",
        "       temp=list_index[i]\n",
        "       list_index[i]=list_index[i]\n",
        "       list_index[j]=temp\n",
        "     return list_index\n"
      ],
      "metadata": {
        "id": "GdBs6OODt2RG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bot_response(user_input):\n",
        "  user_input=user_input.lower()\n",
        "  sentence_list.append(user_input)\n",
        "  bot_response=''\n",
        "  cm=CountVectorizer().fit_transform(sentence_list)\n",
        "  similarity_scores=cosine_similarity(cm[-1],cm)\n",
        "  similarity_scores_list=similarity_scores.flatten()\n",
        "  index=index_sort(similarity_scores_list)\n",
        "  index=index[1:]\n",
        "  response_flag=0\n",
        "  j=0\n",
        "  for i in range(len(index)):\n",
        "    if similarity_scores_list[index[i]]>0.0:\n",
        "      bot_response=bot_response+''+sentence_list[index[i]]\n",
        "      response_flag=1\n",
        "      j=j+1\n",
        "      if j>2:\n",
        "        break\n",
        "        if response_flag ==0:\n",
        "          bot_response=bot_response+''+\"I appologize\"\n",
        "          sentence_list.remove(user_input)\n",
        "          return bot_response"
      ],
      "metadata": {
        "id": "TXFxUERPvOX1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Bot: I am  Sport Chatbot.')\n",
        "exit_list=['exit','see you later','bye']\n",
        "while(True):\n",
        "  user_input=input()\n",
        "  if user_input.lower() in exit_list:\n",
        "   print('Bot: chat with later.')\n",
        "  break\n",
        "else:\n",
        "  if greeting_response(user_input)!=None:\n",
        "      print('Bot:'+greeting_response(user_input))\n",
        "  else:\n",
        "      print('Bot:'+bot_response(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqKFDMkWxpWF",
        "outputId": "d70653e8-220b-42ca-88af-7cbfe2a71ea9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: I am  Sport Chatbot.\n",
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_input='hello world'\n",
        "sentence_list.append(user_input)\n",
        "bot_response=''\n",
        "cm=CountVectorizer().fit_transform(sentence_list)\n",
        "similarity_scores=cosine_similarity(cm[-1],cm)\n",
        "similarity_scores_list=similarity_scores.flatten()\n",
        "index=index_sort(similarity_scores_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "kv-ky5wRzFjy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Go237th-72PP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}